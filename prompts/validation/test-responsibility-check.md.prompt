# Test Responsibility Boundary Validation (Simplified Architecture)

## Objective
Ensure BDD tests maintain proper boundaries between behavior specification and implementation details, with clear responsibility separation for our simplified architecture approach.

## When to Use
- After implementing each scenario
- When tests become complex or hard to maintain
- Before scenario completion to ensure test quality
- When debugging test failures or flakiness

## Required Reading
**MUST read these files before validation:**

Use the Read tool to load:
1. Current feature file: `tests/{feature}/story.feature`
2. Step implementations: `tests/{feature}/{given,when,then}_*.py`
3. Domain model: `docs/domain-model.md` - For business rule reference
4. User story: `docs/user-stories/{feature}.md` - For expected behavior
5. `prompts/reference/python-coding-style.md.prompt` - For simplified architecture coding standards

## Test Responsibility Framework for Simplified Architecture

### Level 1: Feature File (Behavior Specification)
**ONLY specifies WHAT the system should do**

**Correct Feature Content:**
```gherkin
Feature: Submit Command
  
  Scenario: Submit command to online idle client
    Given client "client-001" exists with status "ONLINE" and availability "IDLE"
    When I POST to "/commands" with:
      """
      {
        "client_id": "client-001", 
        "content": "ls -la"
      }
      """
    Then response status code should be 200
    And response body should match:
      """
      {
        "command_id": "{uuid}",
        "status": "PENDING"
      }
      """
```

**Feature File Validation Checklist:**
- [ ] **Business language**: Uses domain terminology, not implementation details
- [ ] **External perspective**: Describes system behavior from user viewpoint  
- [ ] **Observable outcomes**: All Then steps verify observable system responses
- [ ] **No implementation details**: No references to classes, methods, or internal structure
- [ ] **Domain-focused**: Steps relate to business concepts (Client, Command, etc.)

### Level 2: Step Definitions (Behavior Implementation)
**Translates business language to system actions using simplified architecture**

**Step Responsibility Boundaries:**

**Given Steps - Test Data Setup:**
```python
# tests/{feature}/given_create_client_with_status.py
from conftest import TestContext
from brief_bridge.entities.client import Client
from brief_bridge.repositories.client_repository import ClientRepository

def invoke(ctx: TestContext) -> None:
    """
    Business rule: client.registration - setup test client with specific status
    ✅ RESPONSIBLE FOR: Setting up test preconditions
    ❌ NOT RESPONSIBLE FOR: Business logic implementation
    """
    # ✅ Correct: Simple data structures, dependency injection for repository
    client = Client(ctx.client_id, {"hostname": "test-host"})
    client.status = ctx.status
    client.availability = ctx.availability
    
    # Uses repository interface (injected dependency)
    client_repository = ctx.injected_client_repository
    await client_repository.save(client)
```

**When Steps - Action Execution:**
```python
# tests/{feature}/when_submit_api_request.py
from conftest import TestContext
from brief_bridge.use_cases.submit_command_use_case import SubmitCommandUseCase
import json

def invoke(ctx: TestContext) -> None:
    """
    ✅ RESPONSIBLE FOR: Triggering system actions
    ❌ NOT RESPONSIBLE FOR: Validating business rules
    """
    # ✅ Correct: Simple request structure - framework converts to dict
    request = {
        "client_id": ctx.client_id,
        "content": json.loads(ctx.request_body)["content"]
    }
    
    # Use injected UseCase with mocked dependencies
    use_case = ctx.injected_submit_command_use_case
    ctx.last_response = await use_case.execute(request)
```

**Then Steps - Outcome Verification:**
```python
# tests/{feature}/then_verify_response_status.py
from conftest import TestContext

def invoke(ctx: TestContext) -> None:
    """
    ✅ RESPONSIBLE FOR: Verifying observable outcomes
    ❌ NOT RESPONSIBLE FOR: Internal system state verification
    """
    # ✅ Correct: Verifies external system response
    assert ctx.last_response["status"] == "success"
    assert "command_id" in ctx.last_response
```

**Step Implementation Validation Checklist:**
- [ ] **Given steps**: Only set up test preconditions using entities and dependency injection
- [ ] **When steps**: Only trigger system actions, capture responses
- [ ] **Then steps**: Only verify observable system outputs
- [ ] **No business logic**: Steps delegate to entities/UseCases, don't implement rules
- [ ] **Dependency injection**: Use injected repositories and UseCases for testability

### Level 3: Entity/UseCase Layer (Business Logic Implementation)
**WHERE business rules are actually implemented and tested**

**Business logic belongs here:**
```python
# brief_bridge/entities/client.py
class Client:
    def assign_command(self, command_id: str, content: str) -> None:
        """Business rule: client.concurrency - one command per client"""
        if self.has_active_command():
            raise ClientBusyError("Client already executing command")
        self.current_command = {"id": command_id, "content": content}
        self.availability = "BUSY"
        
    def can_accept_new_command(self) -> bool:
        """Business rule: command.target_validation"""
        return self.status == "ONLINE" and self.availability == "IDLE"

# brief_bridge/use_cases/submit_command_use_case.py
class SubmitCommandUseCase:
    def __init__(self, client_repo: ClientRepository, command_repo: CommandRepository):
        self._client_repo = client_repo  # Injected dependency
        self._command_repo = command_repo  # Injected dependency
        
    async def execute(self, request: dict) -> dict:
        """UseCase orchestrates business operations"""
        client = await self._client_repo.find(request["client_id"])
        if not client.can_accept_new_command():  # Business rule in entity
            raise ClientNotAvailableError()
            
        command_id = str(uuid.uuid4())
        client.assign_command(command_id, request["content"])  # Business rule in entity
        await self._command_repo.save(command_id, request["content"])
        
        return {"status": "success", "command_id": command_id}
```

## Common Test Responsibility Violations (Simplified Architecture)

### Violation 1: Business Logic in Steps

**❌ Wrong: Business rule implemented in step**
```python
def invoke(ctx: TestContext) -> None:
    client = Client(ctx.client_id, {"hostname": "test-host"})
    # ❌ Business logic in test step
    if ctx.status == "OFFLINE":
        client.status = "OFFLINE"
        client.availability = "IDLE"
        client.last_heartbeat = datetime.now() - timedelta(minutes=10)
    else:
        client.status = "ONLINE"
        client.availability = "IDLE"
        client.last_heartbeat = datetime.now()
```

**✅ Correct: Delegate to entity**
```python
def invoke(ctx: TestContext) -> None:
    client = Client(ctx.client_id, {"hostname": "test-host"})
    # ✅ Entity handles business logic
    if ctx.status == "OFFLINE":
        client.mark_offline()
    else:
        client.mark_online()
```

### Violation 2: Implementation Details in Feature File

**❌ Wrong: Technical implementation in Gherkin**
```gherkin
Scenario: Database constraint validation
  Given a Client entity exists in memory repository
  When I call SubmitCommandUseCase.execute() method
  Then a ClientNotAvailableError should be raised
```

**✅ Correct: Business behavior focus**
```gherkin  
Scenario: Reject command to busy client
  Given client "client-001" is already executing a command
  When I submit command "ls -la" to client "client-001"
  Then command submission should be rejected with "Client busy" error
```

### Violation 3: Internal State Verification in Then Steps

**❌ Wrong: Verifying internal object state**
```python
def invoke(ctx: TestContext) -> None:
    # ❌ Accessing internal state
    client = ctx.created_client
    assert client.availability == "BUSY"
    assert client.current_command["id"] == ctx.expected_command_id
```

**✅ Correct: Verifying observable system response**
```python
def invoke(ctx: TestContext) -> None:
    # ✅ Verifying external system response
    response = ctx.last_response
    assert response["status"] == "success"
    assert "command_id" in response
```

## Test Boundary Validation Process

### Step 1: Feature File Analysis

**Check each scenario for:**
- [ ] **User perspective**: Scenario reads like user requirement
- [ ] **Business language**: Uses domain terms, not technical jargon
- [ ] **Black box**: No internal implementation references
- [ ] **Observable**: All outcomes are externally verifiable

### Step 2: Given Steps Analysis  

**For each Given step:**
- [ ] **Precondition only**: Sets up required system state
- [ ] **Entity usage**: Uses entities with business logic
- [ ] **No business logic**: Delegates logic to entity layer
- [ ] **Dependency injection**: Uses injected repositories

### Step 3: When Steps Analysis

**For each When step:**
- [ ] **Action trigger**: Only triggers system actions via UseCases
- [ ] **Response capture**: Captures responses for verification
- [ ] **No validation**: Doesn't validate outcomes (That's Then's job)
- [ ] **Simple data**: Uses simple data structures (dict, simple classes)

### Step 4: Then Steps Analysis

**For each Then step:**
- [ ] **Observable verification**: Only checks external system responses
- [ ] **No internal access**: Doesn't access internal object state
- [ ] **UseCase agnostic**: Doesn't know about internal UseCase implementation
- [ ] **User perspective**: Verifies what user would observe

### Step 5: Business Logic Location Check

**Verify business rules are in correct layer:**
- [ ] **Client management**: Rules in Client entity
- [ ] **Command processing**: Rules in Command entity and UseCases  
- [ ] **UseCase orchestration**: Rules coordinated via dependency injection
- [ ] **Validation rules**: Rules in entity methods

## Responsibility Matrix (Simplified Architecture)

| Component | Feature File | Given Steps | When Steps | Then Steps | Entities | UseCases |
|-----------|-------------|-------------|------------|-------------|----------|----------|
| **Business Requirements** | ✅ Specify | ❌ No | ❌ No | ❌ No | ✅ Implement | ✅ Orchestrate |
| **Test Data Setup** | ❌ No | ✅ Coordinate | ❌ No | ❌ No | ❌ No | ❌ No |
| **System Actions** | ✅ Specify | ❌ No | ✅ Trigger | ❌ No | ❌ No | ✅ Execute |
| **Outcome Verification** | ✅ Specify | ❌ No | ❌ No | ✅ Verify | ❌ No | ❌ No |
| **Business Logic** | ❌ No | ❌ No | ❌ No | ❌ No | ✅ Implement | ✅ Coordinate |
| **Dependency Injection** | ❌ No | ✅ Use | ✅ Use | ❌ No | ❌ No | ✅ Require |

## Validation Commands

**Check for business logic in steps:**
```bash
# Look for business rule implementation in test steps
grep -r "if.*status\|if.*availability\|Business.*rule" tests/*/given_*.py tests/*/when_*.py tests/*/then_*.py
```

**Check for dependency injection usage:**
```bash
# Look for proper dependency injection in steps
grep -r "ctx\.injected_" tests/
```

**Check feature file language:**
```bash
# Look for technical implementation details
grep -r "UseCase\|Repository\|Entity\|class\|method" tests/*/story.feature
```

## Remediation Guidelines

### Fix Business Logic in Steps
1. **Move logic to entities**
2. **Update steps to use entity methods**  
3. **Ensure proper separation of concerns**

### Fix Implementation Details in Features
1. **Rewrite scenarios from user perspective**
2. **Use business language instead of technical terms**
3. **Focus on observable system behavior**

### Fix Internal State Verification
1. **Replace with external system verification**
2. **Use response data or observable interfaces**
3. **Test behavior, not implementation**

### Improve Testability
1. **Use dependency injection in steps**
2. **Mock external dependencies**
3. **Keep data structures simple**

## Completion Checklist

### Feature Files
- [ ] All scenarios use business language
- [ ] No implementation details referenced
- [ ] All outcomes are observable externally
- [ ] Scenarios read like user requirements

### Step Implementations
- [ ] Given steps only set up preconditions with entities
- [ ] When steps only trigger actions via UseCases
- [ ] Then steps only verify observable outcomes
- [ ] No business logic implemented in any steps
- [ ] Dependency injection used properly

### Entity/UseCase Integration
- [ ] All business rules implemented in entities
- [ ] UseCases orchestrate via dependency injection
- [ ] Clear separation between test and business logic
- [ ] Two-level testing strategy implemented

### Simplified Architecture Compliance
- [ ] Tests focus on behavior, not implementation
- [ ] Architecture remains simple and testable
- [ ] No over-engineering in test setup
- [ ] Clear responsibility boundaries maintained

## Next Steps

**If validation passes:**
✅ Test boundaries are correct - scenario ready for completion

**If violations found:**
🔧 Fix responsibility violations:
1. Move business logic from steps to entities
2. Implement proper dependency injection
3. Simplify test setup
4. Focus on observable behavior

**For ongoing quality:**
📋 Apply these validation criteria to all future scenarios with simplified architecture in mind